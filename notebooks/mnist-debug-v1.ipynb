{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from lib.Tensor import Tensor\n",
    "from lib.NN import ReLU, Dense, Module, CategoricalCrossEntropyLoss\n",
    "from lib.Optimizers import SGD\n",
    "from lib.data_utils import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/beneverman/Documents/Coding/bens-mini-dl/data\"\n",
    "x_train, y_train, x_valid, y_valid = get_mnist(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 784\n",
      "output_dim: 10\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = Tensor(x_train, requires_grad=False) # (50000, 784) (num_examples, num_features)\n",
    "y_train_tensor = Tensor(y_train, requires_grad=False) # (50000,) (num_examples,)\n",
    "x_valid_tensor = Tensor(x_valid, requires_grad=False) # (10000, 784) (num_examples, num_features)\n",
    "y_valid_tensor = Tensor(y_valid, requires_grad=False) # (10000,) (num_examples,)\n",
    "\n",
    "input_dim = x_train_tensor.shape[1] # number of features (pixels) (784)\n",
    "output_dim = len(set(y_train_tensor.data)) # all unique class labels (10)\n",
    "\n",
    "print(f\"input_dim: {input_dim}\") # 784\n",
    "print(f\"output_dim: {output_dim}\") # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = Dense(input_dim, 64) # (784, 64)\n",
    "        self.relu1 = ReLU() # (64,)\n",
    "        self.fc2 = Dense(64, output_dim) # (64, 10)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        x = self.fc1(x) # (batch_size, 64)\n",
    "        x = self.relu1(x) \n",
    "        x = self.fc2(x) # (batch_size, 10)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.fc1.parameters() + self.fc2.parameters()\n",
    "\n",
    "model = MLP(input_dim, output_dim)\n",
    "EPOCHS = 20\n",
    "STEPS = 100 # num of batches per epoch\n",
    "BATCH_SIZE = 64\n",
    "max_batches_per_epoch = math.ceil(len(x_train) / BATCH_SIZE) # handle smaller last batch\n",
    "\n",
    "criterion = CategoricalCrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad() # zero gradients\n",
    "\n",
    "samp = np.random.randint(0, len(x_train_tensor), BATCH_SIZE) # get random indices\n",
    "\n",
    "# get batch and labels\n",
    "batch = x_train_tensor[samp] # get batch\n",
    "labels = y_train_tensor[samp] # get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(batch) # forward pass\n",
    "loss = criterion(out, labels) # calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.biases.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation_op mul, shape :(), grad shape: ()\n",
      "Creation_op , shape :(), grad shape: ()\n",
      "Creation_op mean, shape :(), grad shape: ()\n",
      "Creation_op getitem, shape :(64,), grad shape: (64,)\n",
      "Creation_op add, shape :(64, 10), grad shape: (64, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 640 into shape (64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# backprop\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:135\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreation_op \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m.\u001b[39m_op\u001b[39m}\u001b[39;00m\u001b[39m, shape :\u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, grad shape: \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mshape\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mv\u001b[39m.\u001b[39mgrad\u001b[39m \u001b[39m\u001b[39mis\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo Grad\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# ? USE THIS TO DEBUG AUTOGRAD\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(v, \u001b[39m'\u001b[39m\u001b[39m_backward\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# handle no_grad context manager, even though we technically don't need to because we set the backward method to a no-op `lambda: None`. I've learned that it's better to be safe than sorry\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     v\u001b[39m.\u001b[39;49m_backward()\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:178\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         other\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(out\u001b[39m.\u001b[39mgrad, axis\u001b[39m=\u001b[39maxis_to_sum)\n\u001b[1;32m    177\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         other\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mreshape(other\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mshape) \u001b[39m# ? reshaping here might cause problemns but idk what else to do\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m# Case 5: both are tensors and same shape\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mgrad\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 640 into shape (64,1)"
     ]
    }
   ],
   "source": [
    "loss.backward() # backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # update params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self shape (10000, 64)\n",
      "Other shape (64, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,64) (64,64) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()  \u001b[39m# set model to eval mode\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m out \u001b[39m=\u001b[39m model(x_valid_tensor)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:56\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m---> 56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):   \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x) \u001b[39m# (batch_size, 64)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-debug-v1.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x) \u001b[39m# (batch_size, 10)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:188\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:697\u001b[0m, in \u001b[0;36mforce_tensor_method.<locals>.wrapper\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Tensor):\n\u001b[1;32m    695\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    696\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput data to layer \u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m need to be a Tensor, is \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:202\u001b[0m, in \u001b[0;36mDense.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBiases must be a 1D tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases, Tensor), \u001b[39m\"\u001b[39m\u001b[39mBiases must be a Tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m (inputs \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\u001b[39m.\u001b[39;49mT) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbiases\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:146\u001b[0m, in \u001b[0;36mTensor.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSelf shape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    144\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOther shape\u001b[39m\u001b[39m\"\u001b[39m, other\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 146\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49madd(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, other\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    147\u001b[0m out \u001b[39m=\u001b[39m Tensor(out, (\u001b[39mself\u001b[39m, other), \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad \u001b[39mor\u001b[39;00m other\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,64) (64,64) "
     ]
    }
   ],
   "source": [
    "model.eval()  # set model to eval mode\n",
    "out = model(x_valid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(out.data, axis=1)  # get index of max value\n",
    "accuracy = (pred == y_valid_tensor).mean()  # calculate accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
