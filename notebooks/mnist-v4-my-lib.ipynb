{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lib.Tensor import Tensor, no_grad\n",
    "from lib.NN import ReLU, Dense, Module, CrossEntropyLoss\n",
    "from lib.Optimizers import SGD\n",
    "\n",
    "from lib.data_utils import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/beneverman/Documents/Coding/bens-mini-dl/data\"\n",
    "x_train, y_train, x_valid, y_valid = get_mnist(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) # (n images, n pixels)\n",
    "print(y_train.shape) # (class labels,)\n",
    "\n",
    "\n",
    "print(x_valid.shape) # (n images, n pixels)\n",
    "print(y_valid.shape) # (class labels,)\n",
    "\n",
    "input_dim = x_train.shape[1] # number of features (pixels)\n",
    "output_dim = len(set(y_train)) # all unique class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = Tensor(x_train, requires_grad=True)\n",
    "y_train_tensor = Tensor(y_train, requires_grad=True)\n",
    "x_val_tensor = Tensor(x_valid, requires_grad=True)\n",
    "y_val_tensor = Tensor(y_valid, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m MLP(input_dim, output_dim)\n",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_dim: \u001b[39mint\u001b[39m, output_dim: \u001b[39mint\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m Dense(input_dim, \u001b[39m64\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1 \u001b[39m=\u001b[39m ReLU()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2 \u001b[39m=\u001b[39m Dense(\u001b[39m64\u001b[39m, output_dim)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:153\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, input_dim, output_dim)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dim \u001b[39m=\u001b[39m input_dim\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim \u001b[39m=\u001b[39m output_dim\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m Tensor\u001b[39m.\u001b[39;49mrandn(output_dim, input_dim, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m*\u001b[39;49m \u001b[39m0.01\u001b[39;49m \u001b[39m# init backwards (output_dim, input_dim) for computational efficiency\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases \u001b[39m=\u001b[39m Tensor\u001b[39m.\u001b[39mzeros(output_dim, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:74\u001b[0m, in \u001b[0;36mTensor.make_tensor.<locals>.wrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Tensor):\n\u001b[1;32m     73\u001b[0m     other \u001b[39m=\u001b[39m Tensor(other, requires_grad\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:192\u001b[0m, in \u001b[0;36mTensor.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    189\u001b[0m rg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad \u001b[39mor\u001b[39;00m other\u001b[39m.\u001b[39mrequires_grad\n\u001b[1;32m    191\u001b[0m \u001b[39m# Case: dims are (x, y) * (x,)\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m] \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m other\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    193\u001b[0m     other \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[39m# Case: dims are (x,) * (x, y)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = Dense(input_dim, 64)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = Dense(64, output_dim)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor[0:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (64,) (64,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m model(x_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/bens-mini-dl/notebooks/mnist-v4-my-lib.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:56\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m---> 56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/NN.py:129\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m epsilon \u001b[39m=\u001b[39m \u001b[39m1e-12\u001b[39m\n\u001b[1;32m    128\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mclip(epsilon, \u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m epsilon) \u001b[39m# clip to avoid log(0)\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m ce \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m (y \u001b[39m*\u001b[39;49m x\u001b[39m.\u001b[39;49mlog() \u001b[39m+\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m y) \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m x)\u001b[39m.\u001b[39mlog())\u001b[39m.\u001b[39mmean() \u001b[39m# cross entropy\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m ce\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:74\u001b[0m, in \u001b[0;36mTensor.make_tensor.<locals>.wrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Tensor):\n\u001b[1;32m     73\u001b[0m     other \u001b[39m=\u001b[39m Tensor(other, requires_grad\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/Documents/Coding/bens-mini-dl/lib/Tensor.py:194\u001b[0m, in \u001b[0;36mTensor.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, other\u001b[39m.\u001b[39mdata[:, \u001b[39mNone\u001b[39;00m])\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmultiply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, other\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    196\u001b[0m out \u001b[39m=\u001b[39m Tensor(out, (\u001b[39mself\u001b[39m, other), \u001b[39m'\u001b[39m\u001b[39mmul\u001b[39m\u001b[39m'\u001b[39m, requires_grad\u001b[39m=\u001b[39mrg)\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (64,) (64,10) "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i in range(0, len(x_train_tensor), batch_size):\n",
    "        x_batch = x_train_tensor[i:i+batch_size] # TODO add data shuffling\n",
    "        y_batch = y_train_tensor[i:i+batch_size] # TODO add data shuffling\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x_batch)\n",
    "\n",
    "        loss = criterion(output, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data * x_batch.shape[0]\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with no_grad():\n",
    "        for i in range(0, len(x_val_tensor), batch_size):\n",
    "            x_batch = x_val_tensor[i:i+batch_size]\n",
    "            y_batch = y_val_tensor[i:i+batch_size]\n",
    "\n",
    "            output = model(x_batch)\n",
    "\n",
    "            loss = criterion(output, y_batch)\n",
    "\n",
    "            val_loss += loss.data * x_batch.shape[0]\n",
    "\n",
    "    train_loss = train_loss / len(x_train_tensor)\n",
    "    val_loss = val_loss / len(x_val_tensor)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | Train Loss: {train_loss:0.4f} | Val Loss: {val_loss:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
